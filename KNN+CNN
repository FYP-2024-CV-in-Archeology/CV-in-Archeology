import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2 as cv
import os
import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as mp
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

def image_to_feature_vector(image, size=(500, 500)):
    # resize the image to a fixed size, then flatten the image into
    # a list of raw pixel intensities
    return cv.resize(image, size).flatten()
length = 0
data = []
imgs = []
names = []
for dirname, _, filenames in os.walk('/kaggle/input/'):
    for filename in filenames:
        path = os.path.join(dirname, filename)
        #print(path)
        img = cv.imread(path)
        vec = image_to_feature_vector(img)
        data.append(vec)
        names.append(filename)
        length+=1
label = [[i] for i in range(length)]
try:
   del X_train, y_train
   del X_test, y_test
   print('clear!')
except:
   pass
X = np.array(data)
y = np.array(label)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
print(len(X_train), len(X_test), len(y_train))
print(type(X_train),type(y_train))

N = 15
#number of clusters

from sklearn.cluster import KMeans
KM = KMeans(n_clusters=N, n_init='auto', random_state=147)
KM.fit(X)
pred = KM.labels_

pred_l = len(pred)
cnt = np.zeros(N)
for i in range(pred_l):
    cnt[pred[i]]+= 1
plt.bar(range(len(cnt)), cnt, label='count',fc='cyan')
plt.xticks(np.arange(0, N, 1))
plt.ylabel('number of pictures')
plt.xlabel('cluster label')
for i in range(N):
    plt.text(i,cnt[i],str(cnt[i]),ha = 'center', va = 'bottom')
plt.legend()
plt.grid()
plt.show()

for i in range(N):
    os.makedirs('/kaggle/working/'+str(i)+'/')
imgs = []
l = len(pred)
inputdir = '/kaggle/input/cropped/sample_outputs'
for i in range(l):
    input_path = os.path.join(inputdir, names[i])
    img = cv.imread(input_path)
    outputdir = '/kaggle/working/' + str(pred[i]) + '/'
    output_path = os.path.join(outputdir, names[i])
    x = np.array(img)
    x = x / 255.0
    imgs.append(x)
    print(names[i],pred[i],output_path)
    cv.imwrite(output_path, img, [cv.IMWRITE_JPEG_QUALITY, 50])

##tingting
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import datasets
import matplotlib.pyplot as plt
from tensorflow.keras import datasets
train_images = imgs
train_labels = pred

for i in range(310):
    if (len(train_images[i][0]) != 1000):
        print(len(train_images[i][0]),i)
print(train_images[118][0][670])
train_images[118] = train_images[0]
print(train_images[118][0][999])
# No.118 not enough dimensionsï¼Œ 671<1000, handling for spec cases
t2 = train_images
t2 = np.array(t2)
t3 = t2[:,:,250:750,:]
t4 = t2[:,150:374,400:624,:]
#print(t3.shape)
#print(t4.shape)

model = Sequential()
model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(4,4)))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
#model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))

model.add(Flatten())
model.add(Dense(units=256,activation="relu"))
#model.add(Dense(units=256,activation="relu"))
model.add(Dense(units=N, activation="softmax"))

print(model.summary())

from keras.optimizers import Adam
opt = Adam(lr=0.001)
model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

train_model = model.fit(t4, train_labels, epochs=50, validation_split=0.2);

test_loss, test_acc = model.evaluate(t4, train_labels)
print("Model - CNN - test loss:", test_loss)
print("Model - CNN - test accuracy:", test_acc * 100)

import plotly.graph_objs as go
from plotly import subplots
from plotly.offline import iplot

def create_trace(x,y,ylabel,color):
        trace = go.Scatter(
            x = x,y = y,
            name=ylabel,
            marker=dict(color=color),
            mode = "markers+lines",
            text=x
        )
        return trace
    
def plot_accuracy_and_loss(train_model):
    hist = train_model.history
    acc = hist['accuracy']
    val_acc = hist['val_accuracy']
    loss = hist['loss']
    val_loss = hist['val_loss']
    epochs = list(range(1,len(acc)+1))
    
    trace_ta = create_trace(epochs,acc,"Training accuracy", "Green")
    trace_va = create_trace(epochs,val_acc,"Validation accuracy", "Red")
    trace_tl = create_trace(epochs,loss,"Training loss", "Blue")
    trace_vl = create_trace(epochs,val_loss,"Validation loss", "Magenta")
   
    fig = subplots.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',
                                                             'Training and validation loss'))
    fig.append_trace(trace_ta,1,1)
    fig.append_trace(trace_va,1,1)
    fig.append_trace(trace_tl,1,2)
    fig.append_trace(trace_vl,1,2)
    fig['layout']['xaxis'].update(title = 'Epoch')
    fig['layout']['xaxis2'].update(title = 'Epoch')
    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])
    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,2])

    
    plot(fig, filename='accuracy-loss')

plot_accuracy_and_loss(train_model)

y = model.predict(t4)

predictions = np.argmax(model.predict(t4),axis=1)

predictions

print(output_path)
l = len(predictions)
inputdir = '/kaggle/input/cropped/sample_outputs'
for i in range(l):
    input_path = os.path.join(inputdir, names[i])
    img = cv.imread(input_path)
    #print(img.shape)
    outputdir = '/kaggle/working/' + str(predictions[i]) + '/'
    output_path = os.path.join(outputdir, names[i])
    print(names[i],predictions[i],output_path)
    cv.imwrite(output_path, img, [cv.IMWRITE_JPEG_QUALITY, 50])

!zip -r file.zip /kaggle/working
#compress files

!rm -rf /kaggle/working/*
#clear outputs
